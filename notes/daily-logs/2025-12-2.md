# Daily Learning Log

## Date: 2025-12-2

### ðŸŽ¯ Today's Focus

- [X] AMAZON S3
- [X] Hands-on lab

### ðŸ“– What I Learned

1. **S3 Overview**

   - Amazon S3 Use cases
   - Amazon S3 - Buckets
   - Amazon S3 - Objects

2. **S3 Hands-on**

   - So choose the region you want to create your bucket in, and we'll see that Amazon S3 still has a view over all your buckets across all regions.

   - Now there's a bucket type that you may or may not see. So if you're in some regions where it's available, you will see general purpose or directory new or more region.

   - So your bucket name must be unique across all regions and all accounts ever created in AWS.

   - So next for object ownership. Right now you have ACL disabled. This is recommended. This is a security setting.

   - Now for blocking public access to this bucket, again, we'll leave this enabled. So we'll block all public access, and we want to have maximum security in our bucket, so only us can upload files to it.

   - Next for bucket versioning. So we want to disable bucket versioning right now, and we'll see later on how to enable it.

   - And for default encryption, I'm going to use server-side encryption with Amazon S3 managed key. So all my objects are going to be encrypted, and I will choose the first option.

   - And bucket key, I will enable it. and then created the bucket, And now it has been successfully created. And you will see here in this UI all your buckets. If you have directory enabled, you will see also directory buckets,

   - But your general purpose buckets are here. And this will deploy buckets for all AWS regions, not just the one you're in right now, but all regions.

   - So I'm going to click on it and have a look at it inside. And now in my bucket, I would like to start uploading objects because currently you have zero objects.

   - So let's click on upload, and then we can add files. And navigate into your code, go into the S3 folder, and then you will find a coffee.jpg file. then upload the files and click on close.

   - And now back into my S3 bucket. I can see the coffee.jpg file is under my objects. So I can do is now click on it and have more details around that file.

   - So now we want to open this object and see if we can open it. We can view it because we have uploaded it onto our Amazon S3 buckets. Therefore, I'm going to click on open.

   - But if I go back to my overview and click on this object url over here. So I copy it, I paste it, and I enter it. I get an access denied. And this access denied tells me that I cannot access my object using what's called the public URL.

   - So what's the difference? Well, this URL right here, if you have a look at it, the beginning is exactly the same, but then the rest is a very, very complicated and long URL, because it's called an S3 pre-signed URL. Why? Well, because this URL contains actually a signature that verifies that I am the one making the request, and therefore it has my credentials in it.

   - And so because my credentials are encoded in this URL, then Amazon S3 says, "Well,(MY OWN BUCKET NAME) is allowed to view his own object, therefore I will display it." So this public URL does not work, but this pre-signed URL with my own credentials works, and of course, this URL is only for me.

   - So we'll see how to make that object public later on, so that the public URL will function as well. So let's go back into our bucket, And I have one object, but I can create a folder.

   - And this folder name may be called images. So we scroll down and create this folder. So now I have the images folder in my bucket. I can click on it, and within it, I can upload again a file.

   - And this time, I will upload the beach.jpg file into, as you can see, the destination is my images folder within my S3 buckets. So let's upload this. Close this.

   - You know, the cloud storage service you used to know such as Google Drive or Dropbox, or whatever you want. Here, we have something very similar in terms of the user experience on Amazon S3.

   - So, of course, I can go to images and I can delete this folder entirely.

3. **Amazon S3 â€“ Security**

   - S3 Bucket Policies

4. **S3 Security- Bucket policy hands-on**

   - So that we can access this coffee file from the public URL.

   - So to do so, let's go under the Permission tabs. And the first thing we have to do is to allow public access from the bucket setting, because right now everything is blocked.

   - So we edit this and we're going to un tick this, and, therefore, we will allow public access. But again, this is something you would disable only, and only if, you know you want to set a public bucket policy.and click on save changes.

   - So now, under Permissions overview,the access that objects can be public.

   - Next, we scroll down and we look at Bucket policy. So currently we have none and we wanna create one so that we make our entire bucket public. So the first thing you can do is look at the policies example, and this is the documentation, and it will show you a lot of use cases on the right hand side that will show you what's the appropriate and corresponding bucket policy.

   - But for us, we're going to use the policy generator. and we're going to create an S3 Bucket Policy. So let's select the right type. We'll allow, and then the principal is going to be a * because we want to allow anyone on the Amazon S3 service to perform, and because we will read objects on our bucket, we want to perform a getObject.

   - We want to allow getObjects in action tab. And the Amazon Resource Name must be the bucket name with a slash, and then with a *.

   - So back into our S3 buckets, we have the bucket arn here, the Amazon resource name here. So we copy it, we paste it into the Amazon Resource Name, We add a slash and then we add a *. And the reason why we do this is that this action, the getObject action right here, applies to objects within your buckets, and, therefore, objects within your bucket are after a slash and there are* to represent these objects.

   - Then add the statement and then generate the policy, then we copy the policy and paste it inside bucket policy and then save changes.

   - So, now, let's go into our object, coffee.jpg, and let's find the object URL, right here. We copy it and we enter it. And as you can see now, my coffee image is fully visible and it is public as well as any other objects in my Amazon S3 buckets.

5. **S3 Website Overview**

   - Amazon S3 can be used to create aesthetic websites.

6. **S3 Website Hands-on**

   - But first, I'm going to upload one more file here, and let's go into Properties, scroll down, and all the way down you will find the static website hosting. So click on Edit, and here we will enable static website hosting.

   - We want to host a static website and we need to specify an index document. So I will say, index.html and we will have to upload that file.This is the default or homepage of the websites.

   - So this is saved, and go back into our objects. And the one thing that's missing here is that index, that HTML file. So let's go to upload this, we Add files and then I will click on index.html and then upload, close it.

   - It's created, so now back into Properties, let's scroll all the way down, and you see now that's under static website hosting, we have a bucket website endpoint. So I copy this URL, paste it, and I get, I love coffee. Hello world! And my coffee.jpg file.

7. **S3 Versioning Overview**

   - Because we've seen how to create a website, but it would be nice to be able to update it in a safe way.

8. **S3 Versioning Hands-on**

   - And so first you need to go into the properties tab and then we have a bucket versioning setting. We're going to edit this and we're going to enable it. And this is to enable bucket versioning.

   - And therefore any files we override now is just going to add versions into our buckets.Let's go into our objects and say we want to update our website. So let's go back, find the website URL. so we have "I love coffee" but let's say we want to write, "I really love coffee" so therefore let's go back into our html file. And I'm going to edit it and save it.

   - And now I upload this file again. So I'm going to add a file and it will be my index.html. And now we have updated content in that file. So if I upload it. It's successful. So now it's been overwritten.

   - But what did happen in the back? Well, we have here this toggle "Show versions" we're going to show the actual version ID with the files. And so we can notice a few things.

   - Number one, the files that we had uploaded before such as the beach.jpg and the coffee.jpg have a null version id. That's because they were uploaded before we had enabled versioning. But this file index.html as you can see has two versions. One has version ID null, which is the file we had uploaded before enabling versioning.

   - But the file we uploaded just right now has a version ID. And therefore, by updating this file and uploading it into our S3 bucket, we have created a new version ID.

   - So now thanks to versioning what we can do is we can actually roll-back our page.

   - So if i delete my html file with version ID and delete permanently it's can be restore but if i delete my image  with only delete is going to show it's back as delete marker and if i load my website the image won't show (ctrl+shift+r to force refresh) but to restore it back i am going to delete the delete marker and if i refresh my webpage the image we be showing.

9. **S3 Replication (CRR & SRR) Overview**

   - So CRR is for cross-region replication and SRR is for same-region replication. The idea is that we have an S3 Bucket in one region and a target S3 Bucket in another region, and we want to set up asynchronous replication between these two buckets.

10. **S3 Replication Hands On**

    - For this, we're going to create a new bucket.and I will set it in one region that I want.

    - and then data will be replicated from this bucket to another bucket. So the thing I need to do of course, is to enable versioning because replication only works if versioning is enabled.

    - So I will create this bucket, and then open this bucket in a new tab and I will create a second bucket and this will be my target bucket.

    - And this time, the region can be either the same, for example, if you wanted to do same region replication or something completely different, for example if you wanted the US, you could do US east one to replicate from Europe to the US. and let's again, enable bucket versioning on the target buckets.

    - So we now have two bucket one origin and the other we wanted to replicated to target bucket so i will upload file on the origin bucket and we can now set replication rule under management tab.

    - And in terms of rule scope, we'll apply it to all objects in the buckets. Now for the destination, we can specify a bucket in this account or in other accounts, and we'll choose one in this account and the bucket name is my target bucket.

    - The destination region was identified as being US east one, so therefore, this is a cross region replication. Okay, now for IAM role, we need to actually go and create a new role for this.

    - Let's just save this. So we get a prompt right here, which says, do you want to replicate existing objects? So it turns out that when you do enable replication, it will only replicate objects from the moment you set it.

    - So for newer uploads. So if you wanted to replicate the previous objects from the source of the destination bucket, you could use something called a batch operation, an S3 batch operation to do so and you would need to say yes, replicate existing objects, but this is separate from the replication feature itself. Therefore, I'm going to say no, do not replicate existing objects.

    - And now what I'm going to do is check in my replica bucket. Of course, if I refresh now, we see that the objects haven't been replicated. So I'm going to do is now upload a new file.

    - Now, if we go in my target bucket and refresh this, it's gonna take maybe five seconds. And this took about 10 seconds on the first replication, but we can see that my coffee.jpeg has been added into my replica bucket. And if I show the versions, we can see the version ID of my coffee.jpeg is the exact same of the origin bucket.

### ðŸ’» Hands-on Practice

```code
# Code examples here
