# Daily Learning Log

## Date: 2025-12-5

### ðŸŽ¯ Today's Focus

- [X] RDS & AURORA
- [X] Database
- [X] Hands-on lab

### ðŸ“– What I Learned

1. **RDS Deployments Options**

    - So when you're deploying RDS databases, you have multiple options. The first one is called Single-AZ deployment. So that means that your database is going to be created in one single availability zone.

    - But say that now you need to scale the read workloads, we have more and more applications that need to read more and more data from RDS. The way you can do it is by creating Read Replica. So that means that there is gonna be some copies, some replicas of your RDS database that are going to be created.

    - So Read Replicas are used to scale read workloads, and you can have up to five Read Replicas for each RDS database instance.

    - Now, when it comes to writing data, writing data is only done to the main database, so your application still have to write to the only one central RDS database.

2. **Amazon ElasticCache Overview**

    - So Amazon ElasticCache is a managed caching service from AWS. And the idea with caching is that you have some data that is very frequently accessed by your applications, and therefore, instead of going to the database every time to get this data, you can store it in memory in a caching layer, so that your application can access it much faster.

    - So ElasticCache supports two major caching engines, Memcached and Redis. And both are in-memory data stores that can be used as caches to speed up data retrieval for applications.

3. **DynamoDB**

    - So DynamoDB is a fully managed NoSQL database service provided by AWS that offers fast and predictable performance with seamless scalability. It is designed to handle large amounts of data and high request rates with low latency.

    - DynamoDB is a serverless database, meaning you don't have to manage any infrastructure or servers. AWS takes care of all the operational aspects, including hardware provisioning, software patching, setup, configuration, replication, and scaling.

    - DynamoDB stores data in tables, which consist of items (similar to rows in a relational database) and attributes (similar to columns). Each item is uniquely identified by a primary key, which can be either a single attribute (partition key) or a combination of two attributes (partition key and sort key).

    - One of the key features of DynamoDB is its ability to scale automatically based on the workload. It can handle sudden spikes in traffic without any manual intervention. You can also set up auto-scaling policies to adjust the read and write capacity units based on your application's needs.

    - DynamoDB supports both provisioned throughput mode and on-demand mode. In provisioned mode, you specify the number of read and write capacity units you need, while in on-demand mode, you pay for the actual read and write requests your application makes.

    - Additionally, DynamoDB offers features like Global Tables for multi-region replication, Streams for capturing data changes, and Time to Live (TTL) for automatic data expiration.

4. **DynamoDB Hands-on**

   - So I'm going to create a table, and I'll call this one DemoTable. Now in DynamoDB what you need to do is specify a partition key, so specify user_id, and sort keys are definitely out of scope for the exam, so let's just consider just the partition key.

   - Now for the settings in DynamoDB, again, I'm going to leave it as a default settings,then click on create table.

   - So our table is now creating, and what I'm going to notice is that we are creating a table without creating a database. So the database already exists, it's serverless, we don't need to provision servers. We just want you to say, "Hey, look, I want this table, please create it for me and I don't care how it's being run." And that's the whole power of DynamoDB, that's the whole power of serverless services.

   - So i can now click on view items and then create an item in DynamoDB, And for user_id I can say 1234, so that will be my user ID. and fill all my schema and click on create item.

   - Now if I can create a second item, so 45678, and then add a new string, so, for example, first_name. and click on Create item. in this example, I didn't fil all the schema like the first for the user, I just specified first name, and it was still accepted by DynamoDB. So it's a very flexible type of database, it's a very flexible way to insert data, and this whole, like, test sets of features and particularities make DynamoDB really, really good.

   - But the difference between DynamoDB and, say, RDS is that DynamoDB will have all the data living within one single table, and there's no way to join it with another table. So it's not a relational database, that's when DynamoDB is a non SQL database, so not only SQL database, so NoSQL. And the idea, here, is that, yes, we cannot link this table to another table, so we need to make sure that all the relevant data is well formatted within our main DynamoDB table.

   - When you're done and ready you can just delete the table. You can delete all the CloudWatch alarms associated with it, and just type delete in this box.

5. **DynamoDB Global Tables**

    - So global tables is a way for you to have multi region replication of your DynamoDB tables. So the idea is that you can create a table in one region, and then replicate it automatically into other regions around the world. And this is fully managed by AWS, so you don't need to do anything on your side.

6. **Redshift Overview**

   - And the idea with Redshift that is really, really good at analyzing data and making some computations.

   - Just a high level overview, but a data warehouse is used to do some computation on your data sets and do some analytics, and possibly build some kind of visualizations through dashboards on it. And so for that use case, Redshift would be perfect.

   - If you're looking for a web data warehousing, or OLAP, Online Analytical Processing, then you need to look at Redshift, which is a warehousing technology.

7. **Elastic MapReduce(EMR) Overview**

   - So Hadoop is an open source technology, and they allow multiple servers that work in a cluster to analyze the data together, and so when you're using EMR.

   - So part of the Hadoop ecosystem, the Big Data ecosystem, you will see projects names such as Apache Spark, HBase, Presto, and Flink, and all these things will be working on top of your Hadoop cluster.

8. **Athena Overview**

    - So Athena is a serverless query service that allows you to analyze data directly in Amazon S3 using standard SQL. It is designed for ad-hoc querying and analysis of large datasets stored in S3 without the need to set up or manage any infrastructure.

    - Athena uses Presto, an open-source distributed SQL query engine, to execute queries. It supports a wide range of data formats, including CSV, JSON, Parquet, ORC, and Avro, making it versatile for different types of data stored in S3.

    - One of the key features of Athena is its serverless architecture. You don't need to provision or manage any servers or clusters. You simply define your schema, write your SQL queries, and Athena takes care of the rest. This makes it easy to get started quickly and scale automatically based on the workload.

    - Athena integrates seamlessly with other AWS services, such as AWS Glue for data cataloging and AWS IAM for access control. You can use the AWS Glue Data Catalog to create and manage your table definitions and schemas, making it easier to organize and query your data.

    - Pricing for Athena is based on the amount of data scanned by your queries. You pay only for the queries you run, making it cost-effective for occasional or ad-hoc analysis.

    - Overall, Athena is a powerful tool for analyzing data stored in S3 using SQL without the need for complex infrastructure setup, making it accessible to a wide range of users.

9. **QuickSight Overview**

   - So behind this very complicated tagline, all you have to remember is that Amazon QuickSight allows you to create dashboards on your databases so we can visually represent your data and show your business users the insights they're looking for, So QuickSight allows you to create all these kind of cool graphs, charts, and so on.

   - AWS serverless service can use machine learning-powered business intelligence to create interactive dashboards such as business analytics

10. **DocumentDB Overview**

    - So the same way we had Aurora as the way for AWS to implement a sort of big cloud native version of PostgreSQL and MySQL, we have DocumentDB, which is an Aurora version for MongoDB.

    - So DocumentDB is a no SQL database and it's based on top of the MongoDB technology.

    - So at the exam, if you see anything related to MongoDB, think DocumentDB, or if you see anything related to no SQL databases, think DocumentDB and also DynamoDB.

11. **Neptune Overview**
    - Fully managed graph database

12. **Timestream Overview**

13. **Managed Blockchain Overview**

    - So there's a decentralization aspect to a Blockchain. So managed Blockchain by Amazon.

14. **Glue Overview**

    - It's a very powerful tool, because you can do any kind of instruction transformation and then you can load it into many different places.

15. **Data Migration Service(DMS) Overview**

    - So the idea with DMS is that you have a source database, which can be on-premises or in AWS, and then you have a target database, which can also be on-premises or in AWS. And DMS will take care of migrating the data from the source to the target.

    - DMS supports both homogeneous migrations, where the source and target databases are of the same type (e.g., Oracle to Oracle), and heterogeneous migrations, where the source and target databases are of different types (e.g., Oracle to Amazon Aurora).

    - One of the key features of DMS is that it allows for continuous data replication. This means that after the initial migration, DMS can keep the source and target databases in sync by continuously replicating changes made to the source database to the target database. This is particularly useful for minimizing downtime during migrations.

    - DMS also provides monitoring capabilities through Amazon CloudWatch, allowing you to track the progress of your migration tasks and receive notifications for any issues that may arise.

    - Overall, DMS is a powerful tool for simplifying and automating the process of database migration, making it easier for organizations to move their data to AWS or between different database engines.

16. **DATABASE & ANALYTICS SUMMARY**

### ðŸ’» Hands-on Practice

```code
# Code examples here
